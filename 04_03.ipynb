{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Rohit-Roby/Project/blob/main/04_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9KLZAhSdLul_",
    "outputId": "b467f3d3-0f07-4b32-9ceb-9bc82ea6f451"
   },
   "outputs": [],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29STvKx7cs4a",
    "outputId": "061fea69-533c-4e52-d159-2e2253894fa1"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade objaverse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "hvClQUfZdLCV",
    "outputId": "80b6b382-7748-4bec-eb4b-ff29c99c61ef"
   },
   "outputs": [],
   "source": [
    "import objaverse as obx\n",
    "obx.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZkYUxsEldR6V",
    "outputId": "670cc199-c313-427c-80f3-63133de15969"
   },
   "outputs": [],
   "source": [
    "uids = obx.load_uids()\n",
    "len(uids), type(uids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V1DHhXY8dZnL",
    "outputId": "43d87b10-6416-4c00-9a82-f234e39fbf3e"
   },
   "outputs": [],
   "source": [
    "uids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J31pnTNPdduV",
    "outputId": "590eb1b1-75e8-45b3-94d4-de205f5527e5",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "annotations = obx.load_annotations(uids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_travel_uids = [uid for uid, annotation in annotations.items() if (len(annotation[\"tags\"]) > 0  and annotation[\"tags\"][0]['name'] == 'places-travel')]\n",
    "place_travel_uids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pOxFXZrZvvzp",
    "outputId": "3dceb2ff-423f-4fae-8815-93fa7006abe7"
   },
   "outputs": [],
   "source": [
    "if len(annotations[uids[1]]['tags']) > 0 : print(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "apwjwzvmvvrj",
    "outputId": "023da150-f70b-467d-d9c8-ff743cd11ffe"
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "processes = multiprocessing.cpu_count()\n",
    "processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1sKhc6uvvi2",
    "outputId": "e594f6ad-d3f4-42ce-a856-ce7797354eed"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(40)\n",
    "# uids = obx.load_uids()\n",
    "random_object_uids = random.sample(uids, 50)\n",
    "random_object_uids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iJTqU1Tfwwof",
    "outputId": "f6ea720e-43b5-4544-984b-013f1672c8ff"
   },
   "outputs": [],
   "source": [
    "objects= obx.load_objects(\n",
    "    uids = random_object_uids,\n",
    "    download_processes = processes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nYhKLJUnwwlg",
    "outputId": "eb4246fe-e55d-4689-9489-63df3de393d4"
   },
   "outputs": [],
   "source": [
    "!pip install trimesh --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xYa72nn-wwfb",
    "outputId": "f73c6e25-465a-4895-88db-b95d4542fd18"
   },
   "outputs": [],
   "source": [
    "lvis_annotations = obx.load_lvis_annotations()\n",
    "lvis_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rdft0n1l2Xmx"
   },
   "source": [
    "use pandas and serialize and sort the descriptions of the 3d model like face count, vertex_count texture count and size, tags, description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.17.1-cp310-cp310-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.23.5)\n",
      "Collecting torch==2.2.1 (from torchvision)\n",
      "  Downloading torch-2.2.1-cp310-cp310-win_amd64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.2.1->torchvision) (3.9.0)\n",
      "Collecting typing-extensions>=4.8.0 (from torch==2.2.1->torchvision)\n",
      "  Downloading typing_extensions-4.10.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.2.1->torchvision) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.2.1->torchvision) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.2.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.2.1->torchvision) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch==2.2.1->torchvision) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch==2.2.1->torchvision) (1.2.1)\n",
      "Downloading torchvision-0.17.1-cp310-cp310-win_amd64.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 36.1 MB/s eta 0:00:00\n",
      "Downloading torch-2.2.1-cp310-cp310-win_amd64.whl (198.6 MB)\n",
      "   ---------------------------------------- 0.0/198.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 4.6/198.6 MB 147.3 MB/s eta 0:00:02\n",
      "   - ------------------------------------- 10.1/198.6 MB 129.6 MB/s eta 0:00:02\n",
      "   --- ----------------------------------- 15.8/198.6 MB 108.8 MB/s eta 0:00:02\n",
      "   ---- ---------------------------------- 21.3/198.6 MB 131.2 MB/s eta 0:00:02\n",
      "   ----- --------------------------------- 26.4/198.6 MB 131.2 MB/s eta 0:00:02\n",
      "   ------ -------------------------------- 31.6/198.6 MB 129.5 MB/s eta 0:00:02\n",
      "   ------- ------------------------------- 36.6/198.6 MB 110.0 MB/s eta 0:00:02\n",
      "   -------- ------------------------------ 41.8/198.6 MB 131.2 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 44.1/198.6 MB 81.8 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 47.8/198.6 MB 81.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 54.2/198.6 MB 93.0 MB/s eta 0:00:02\n",
      "   ----------- --------------------------- 60.7/198.6 MB 131.2 MB/s eta 0:00:02\n",
      "   ------------ -------------------------- 65.8/198.6 MB 110.0 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 70.7/198.6 MB 93.9 MB/s eta 0:00:02\n",
      "   -------------- ------------------------ 76.2/198.6 MB 108.8 MB/s eta 0:00:02\n",
      "   ---------------- ---------------------- 81.6/198.6 MB 108.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 86.6/198.6 MB 93.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 89.3/198.6 MB 93.9 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 93.5/198.6 MB 73.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 98.3/198.6 MB 81.8 MB/s eta 0:00:02\n",
      "   ------------------- ------------------ 102.9/198.6 MB 110.0 MB/s eta 0:00:01\n",
      "   -------------------- ------------------ 106.9/198.6 MB 93.9 MB/s eta 0:00:01\n",
      "   --------------------- ----------------- 110.9/198.6 MB 93.9 MB/s eta 0:00:01\n",
      "   ---------------------- ---------------- 115.3/198.6 MB 93.9 MB/s eta 0:00:01\n",
      "   ---------------------- --------------- 119.7/198.6 MB 108.8 MB/s eta 0:00:01\n",
      "   ------------------------ -------------- 124.5/198.6 MB 93.9 MB/s eta 0:00:01\n",
      "   ------------------------- ------------- 128.7/198.6 MB 93.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------ 132.7/198.6 MB 81.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------ 136.9/198.6 MB 93.9 MB/s eta 0:00:01\n",
      "   --------------------------- ----------- 141.2/198.6 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------- ---------- 146.3/198.6 MB 108.8 MB/s eta 0:00:01\n",
      "   ----------------------------- -------- 151.6/198.6 MB 129.5 MB/s eta 0:00:01\n",
      "   ----------------------------- -------- 155.6/198.6 MB 110.0 MB/s eta 0:00:01\n",
      "   ------------------------------ ------- 160.4/198.6 MB 131.2 MB/s eta 0:00:01\n",
      "   ------------------------------- ------ 165.2/198.6 MB 108.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ----- 170.7/198.6 MB 131.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 174.4/198.6 MB 93.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 178.9/198.6 MB 93.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 184.3/198.6 MB 93.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ - 189.1/198.6 MB 108.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ - 193.3/198.6 MB 108.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  197.8/198.6 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 93.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 93.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 93.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 93.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 93.9 MB/s eta 0:00:01\n",
      "   --------------------------------------- 198.6/198.6 MB 29.7 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Installing collected packages: typing-extensions, torch, torchvision\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.1\n",
      "    Uninstalling torch-1.12.1:\n",
      "      Successfully uninstalled torch-1.12.1\n",
      "Successfully installed torch-2.2.1 torchvision-0.17.1 typing-extensions-4.10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\rr858\\AppData\\Local\\Temp\\pip-uninstall-0412ho_y'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory for dataset\n",
    "dataroot = \"data/celeba\"\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 2\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 128\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 64\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 64\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# Beta1 hyperparameter for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "PUMpxaZM2XBy"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'SymInt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdset\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mvutils\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\torchvision\\__init__.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodulefinder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Module\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\torchvision\\_meta_registrations.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_custom_ops\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlibrary\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Ensure that torch.ops.torchvision is visible\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\torch\\_custom_ops.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_custom_op\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      4\u001b[0m     _custom_op_with_schema,\n\u001b[0;32m      5\u001b[0m     _find_custom_op,\n\u001b[0;32m      6\u001b[0m     infer_schema,\n\u001b[0;32m      7\u001b[0m     parse_qualname,\n\u001b[0;32m      8\u001b[0m     validate_namespace,\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlibrary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_ctx\n\u001b[0;32m     12\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom_op\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimpl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimpl_backward\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     19\u001b[0m ]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\torch\\_custom_op\\impl.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_C\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlibrary\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mlibrary\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_library\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabstract_impl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AbstractImplCtx\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlibrary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_ctx\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autograd_kernel_indirection, construct_autograd_kernel\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\torch\\_library\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_library\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabstract_impl\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_library\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimple_registry\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_library\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\torch\\_library\\abstract_impl.py:117\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    114\u001b[0m         global_ctx_getter \u001b[38;5;241m=\u001b[39m prev\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAbstractImplCtx\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;124;03m    Context object for writing abstract implementations for custom operators.\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, _shape_env, _op):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\torch\\_library\\abstract_impl.py:126\u001b[0m, in \u001b[0;36mAbstractImplCtx\u001b[1;34m()\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape_env \u001b[38;5;241m=\u001b[39m _shape_env\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op \u001b[38;5;241m=\u001b[39m _op\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_unbacked_symint\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSymInt\u001b[49m:\n\u001b[0;32m    127\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    128\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_unbacked_symint is deprecated, please use new_dynamic_size instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    129\u001b[0m     )\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_dynamic_size(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmin\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute 'SymInt'"
     ]
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "torch.use_deterministic_algorithms(True) # Needed for reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##mock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3836733143.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[31], line 11\u001b[1;36m\u001b[0m\n\u001b[1;33m    dataloader = torch.utils.data.DataLoader([for uid in uids : objects[uid]], batch_size=batch_size,\u001b[0m\n\u001b[1;37m                                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# We can use an image folder dataset the way we have it setup.\n",
    "# Create the dataset\n",
    "dataset = dset.ImageFolder(root=dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(image_size),\n",
    "                               transforms.CenterCrop(image_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "# Create the dataloader\n",
    "dataloader = torch.utils.data.DataLoader([for uid in uids : objects[uid]], batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=workers)\n",
    "\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n",
    "# Plot some training images\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original GAN Code (in PyTorch)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        # ... (architecture details)\n",
    "#         self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf*8),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*4),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*2),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            \n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the discriminator class\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        # ... (architecture details)\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(True),\n",
    "            \n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*2),\n",
    "            nn.LeakyReLU(0.2, inplace = True),\n",
    "            \n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*4),\n",
    "            nn.LeakyReLU(0.2, inplace = True),\n",
    "            \n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace = True),\n",
    "            \n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create generator and discriminator instances\n",
    "generator = Generator()\n",
    "print(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=True)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (12): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "discriminator = Discriminator()\n",
    "print(discriminator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize the ``BCELoss`` function\n",
    "# criterion = nn.BCELoss()\n",
    "\n",
    "# # Create batch of latent vectors that we will use to visualize\n",
    "# #  the progression of the generator\n",
    "# fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "# # Establish convention for real and fake labels during training\n",
    "# real_label = 1.\n",
    "# fake_label = 0.\n",
    "\n",
    "# # Setup Adam optimizers for both G and D\n",
    "# optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "# optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=0.001)\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(1000):\n",
    "    # ... (training details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock data for testing\n",
    "mock_data = torch.tensor([[0, 1, 0, 0, 1, 1, 1],\n",
    "                          [1, 0, 1, 1, 0, 0, 1],\n",
    "                          [0, 0, 1, 1, 1, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print mock data and generated results\n",
    "print(\"Mock data:\")\n",
    "print(mock_data)\n",
    "print(\"\\nGenerated data:\")\n",
    "print(generator(mock_data).round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/black0017/3D-GAN-pytorch/blob/master/models/GAN3D.py"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
