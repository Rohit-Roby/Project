{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Rohit-Roby/Project/blob/main/04_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9KLZAhSdLul_",
    "outputId": "b467f3d3-0f07-4b32-9ceb-9bc82ea6f451"
   },
   "outputs": [],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29STvKx7cs4a",
    "outputId": "061fea69-533c-4e52-d159-2e2253894fa1"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade objaverse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "hvClQUfZdLCV",
    "outputId": "80b6b382-7748-4bec-eb4b-ff29c99c61ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import objaverse as obx\n",
    "obx.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZkYUxsEldR6V",
    "outputId": "670cc199-c313-427c-80f3-63133de15969"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(798759, list)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uids = obx.load_uids()\n",
    "len(uids), type(uids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V1DHhXY8dZnL",
    "outputId": "43d87b10-6416-4c00-9a82-f234e39fbf3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8476c4170df24cf5bbe6967222d1a42d',\n",
       " '8ff7f1f2465347cd8b80c9b206c2781e',\n",
       " 'c786b97d08b94d02a1fa3b87d2e86cf1',\n",
       " '139331da744542009f146018fd0e05f4',\n",
       " 'be2c02614d774f9da672dfdc44015219',\n",
       " 'efd35e7d21ac482688c294e3b6c9f74e',\n",
       " '21d5f90dbc9f4f229b0faa7b56b67f3e',\n",
       " 'dcd33159a0864de388de3a08f55e604a',\n",
       " 'a7ad32b5d4d84ee5a40ebbd86da4dbe4',\n",
       " '7d6a14874eed48c2b720f0d1adfe6dd9']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J31pnTNPdduV",
    "outputId": "590eb1b1-75e8-45b3-94d4-de205f5527e5",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 159/160 [00:48<00:00,  3.25it/s]\n"
     ]
    }
   ],
   "source": [
    "annotations = obx.load_annotations(uids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place_travel_uids = [uid for uid, annotation in annotations.items() if (len(annotation[\"tags\"]) > 0  and annotation[\"tags\"][0]['name'] == 'places-travel')]\n",
    "# place_travel_uids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "apwjwzvmvvrj",
    "outputId": "023da150-f70b-467d-d9c8-ff743cd11ffe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "processes = multiprocessing.cpu_count()\n",
    "processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1sKhc6uvvi2",
    "outputId": "e594f6ad-d3f4-42ce-a856-ce7797354eed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['41ab58c332d04f29ad05d5fc4fba0ed2',\n",
       " '76d25a311e3b40a49a8f87c75f87261d',\n",
       " 'd85879152e1940259c2fae8dc800c767',\n",
       " 'a99c66d40fd6481fbdd6373ce483d784',\n",
       " 'c7869bb3c6c14b25b02406f04af3bff5',\n",
       " '6477537d306e44e595695978bf748a1a',\n",
       " '8ba5b25873754e9d9d7a0592163a122b',\n",
       " '19c3affe766740809243fd690afcc93d',\n",
       " '0721ad0fee1c48809eb69d71ad9bc789',\n",
       " '1ddeb59282564ab4a6fdb1c50970a9ea',\n",
       " '53d652be268347a6911587da63e0eac6',\n",
       " '5ca57754a947431786a336c32e9cec13',\n",
       " '93ca6fc690ef405b98914e7b3cf2a10e',\n",
       " '7fd0443d4e4e478b81303abae8e97418',\n",
       " '9eccfca3329a454aa46275a1a4c635d3',\n",
       " 'fb8e47d01e9346239d5738e7fa0ec7dd',\n",
       " '38b9f493fc174e1ca95a5b3ceb62fdf5',\n",
       " '09c86c1a262d4c7eb5fe8f4d86e04f4c',\n",
       " 'c42fe85bb31044919d93e22cce94498b',\n",
       " '1eae12888f514a5ebbb322edcae835e6',\n",
       " '34d4e9d8837549199658133c36643bf0',\n",
       " 'b5a5c8d9fb45446da1400ea2cd1ec9eb',\n",
       " '6e481ea649d248ee9026ba876fce41d4',\n",
       " 'b111bd92b8fa45ee8589416fd4b86dcf',\n",
       " 'f2ae93382d774a6789bb6481b31b9c03',\n",
       " '7362d68dce63459bbd94f14489e7c26b',\n",
       " '18edf463ee424903aa5d9fe3d54a9694',\n",
       " 'bf32c6ae3fcb4f12a22d79c5ee7fc6e3',\n",
       " 'c56b8b96169846e8ac7e82fd59c2a59e',\n",
       " 'b04cfdf560ea47f88d5c091150fd6776',\n",
       " 'a7e04976a0964f70a2611f7b69f18bd7',\n",
       " '637ae8ab0342482a9989be412893448c',\n",
       " '59dda96580a54dcc8be20ccc9de66f12',\n",
       " 'af460ab494c64f2a89b5d1af0b6b1865',\n",
       " '03859fd06f4042d3a875ba2b7153a1cf',\n",
       " 'd9d3ceae786f4fcfb85669c62b3b648b',\n",
       " '5b8beebbf75d43cbb6bddc6a6e23d768',\n",
       " '27a14a4cc527415181df018e03946f11',\n",
       " 'b412bdc49c244712bc0977f2b9ccddd7',\n",
       " '7ced12752fcc4efd89d2d1594e8d5a32',\n",
       " '3fe9b5fd07a54440ad78be70607cd4bc',\n",
       " '3b3f914a71ac4dae9f18fb613532d2be',\n",
       " 'c59822508a4d45918f509e0a5cd60aa3',\n",
       " 'd4964cbaf4e944959f24031370380123',\n",
       " '2f7beb335b404e81ac5c78d413adaa68',\n",
       " '20b0abea116a4a6db2b76d708ea44bcd',\n",
       " '8fe7fbcd06444473b51fbf35ccc8f9c4',\n",
       " '44a673750a304535865e54c759a9cd27',\n",
       " 'a9cf49c12fc34af5bbafbf50ff312113',\n",
       " 'a1987ec9fe2046629e45ac8055f320be']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.seed(50)\n",
    "# uids = obx.load_uids()\n",
    "random_object_uids = random.sample(uids, 50)\n",
    "random_object_uids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iJTqU1Tfwwof",
    "outputId": "f6ea720e-43b5-4544-984b-013f1672c8ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting download of 50 objects with 16 processes\n"
     ]
    }
   ],
   "source": [
    "objects= obx.load_objects(\n",
    "    uids = random_object_uids,\n",
    "    download_processes = processes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rr858\\.objaverse\\hf-objaverse-v1\\glbs/000-038/41ab58c332d04f29ad05d5fc4fba0ed2.glb\n"
     ]
    }
   ],
   "source": [
    "# objects[uids[1]]\n",
    "first_value = next(iter(objects.values()))\n",
    "print(first_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
      "Requirement already satisfied: torch in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: torchvision in c:\\programdata\\anaconda3\\lib\\site-packages (0.17.1)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.2.1-cp310-cp310-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Downloading torchaudio-2.2.1-cp310-cp310-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.7/2.4 MB 21.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.7/2.4 MB 21.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 16.8 MB/s eta 0:00:00\n",
      "Installing collected packages: torchaudio\n",
      "Successfully installed torchaudio-2.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/facebookresearch/pytorch3d.git\n",
      "  Cloning https://github.com/facebookresearch/pytorch3d.git to c:\\users\\rr858\\appdata\\local\\temp\\pip-req-build-bvm5yywb\n",
      "  Resolved https://github.com/facebookresearch/pytorch3d.git to commit b215776f2d4d31c160538dccdbfe7c827d1d3e88\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting fvcore (from pytorch3d==0.7.6)\n",
      "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
      "     ---------------------------------------- 0.0/50.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 50.2/50.2 kB 2.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting iopath (from pytorch3d==0.7.6)\n",
      "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
      "     ---------------------------------------- 0.0/42.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.2/42.2 kB 2.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from fvcore->pytorch3d==0.7.6) (1.23.5)\n",
      "Collecting yacs>=0.1.6 (from fvcore->pytorch3d==0.7.6)\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from fvcore->pytorch3d==0.7.6) (6.0)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from fvcore->pytorch3d==0.7.6) (4.64.1)\n",
      "Requirement already satisfied: termcolor>=1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from fvcore->pytorch3d==0.7.6) (2.3.0)\n",
      "Requirement already satisfied: Pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from fvcore->pytorch3d==0.7.6) (9.4.0)\n",
      "Requirement already satisfied: tabulate in c:\\programdata\\anaconda3\\lib\\site-packages (from fvcore->pytorch3d==0.7.6) (0.8.10)\n",
      "Requirement already satisfied: typing_extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from iopath->pytorch3d==0.7.6) (4.10.0)\n",
      "Collecting portalocker (from iopath->pytorch3d==0.7.6)\n",
      "  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\programdata\\anaconda3\\lib\\site-packages (from portalocker->iopath->pytorch3d==0.7.6) (305.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->fvcore->pytorch3d==0.7.6) (0.4.6)\n",
      "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Building wheels for collected packages: pytorch3d, fvcore, iopath\n",
      "  Building wheel for pytorch3d (setup.py): started\n",
      "  Building wheel for pytorch3d (setup.py): still running...\n",
      "  Building wheel for pytorch3d (setup.py): still running...\n",
      "  Building wheel for pytorch3d (setup.py): finished with status 'done'\n",
      "  Created wheel for pytorch3d: filename=pytorch3d-0.7.6-cp310-cp310-win_amd64.whl size=869041 sha256=0718124e3d5e28f846cb1f397d5badfe863d8b817f83595a59505b7090fa56d0\n",
      "  Stored in directory: C:\\Users\\rr858\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-8j8tfpva\\wheels\\dd\\74\\cc\\b9266c863f19026f796e59a04e1cd9eb3754474a52ce1b66ce\n",
      "  Building wheel for fvcore (setup.py): started\n",
      "  Building wheel for fvcore (setup.py): finished with status 'done'\n",
      "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61417 sha256=48d1eb1561854a1d80300fdfe07a662d538bc563d777a03e281e36671cc0cfd2\n",
      "  Stored in directory: c:\\users\\rr858\\appdata\\local\\pip\\cache\\wheels\\01\\c0\\af\\77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
      "  Building wheel for iopath (setup.py): started\n",
      "  Building wheel for iopath (setup.py): finished with status 'done'\n",
      "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31542 sha256=33c8345b84c78e9a9685ba3c3113d96d6b0a4e01c13a40d4608ff2f76428ba77\n",
      "  Stored in directory: c:\\users\\rr858\\appdata\\local\\pip\\cache\\wheels\\9a\\a3\\b6\\ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n",
      "Successfully built pytorch3d fvcore iopath\n",
      "Installing collected packages: yacs, portalocker, iopath, fvcore, pytorch3d\n",
      "Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-2.8.2 pytorch3d-0.7.6 yacs-0.1.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/pytorch3d.git 'C:\\Users\\rr858\\AppData\\Local\\Temp\\pip-req-build-bvm5yywb'\n"
     ]
    }
   ],
   "source": [
    "pip install \"git+https://github.com/facebookresearch/pytorch3d.git\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import trimesh\n",
    "# from pytorch3d.io import load_gltf\n",
    "from pytorch3d.structures import Volumes\n",
    "from pytorch3d.ops import cubify, subdivide_meshes\n",
    "import numpy as np\n",
    "from scipy.ndimage import zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_voxel_grid(voxel_grid, target_shape):\n",
    "    \"\"\"\n",
    "    Resize a voxel grid to the target shape using trilinear interpolation.\n",
    "    \"\"\"\n",
    "    # Extract voxel data from VoxelGrid object\n",
    "    dense_voxel_grid = voxel_grid.matrix\n",
    "    \n",
    "    # Check if the voxel grid has at least one non-zero dimension\n",
    "    if not any(dense_voxel_grid.shape):\n",
    "        raise ValueError(\"Input voxel grid has an invalid shape.\")\n",
    "\n",
    "    # Check if the voxel grid has a valid rank\n",
    "    if len(dense_voxel_grid.shape) != 3:\n",
    "        raise ValueError(\"Input voxel grid must have a rank of 3 (3D).\")\n",
    "\n",
    "    # Calculate scaling factors for each dimension\n",
    "    scale_factors = [t / s for s, t in zip(dense_voxel_grid.shape, target_shape)]\n",
    "    \n",
    "    # Resize voxel grid using zoom\n",
    "    resized_voxel_grid = zoom(dense_voxel_grid, zoom=scale_factors, mode='nearest')\n",
    "    \n",
    "    return resized_voxel_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glb_to_voxels(glb_file, resolution=64):\n",
    "    \"\"\"\n",
    "    Convert a .glb file to a voxel grid.\n",
    "    \"\"\"\n",
    "    # Load .glb file\n",
    "    scene = trimesh.load(glb_file)\n",
    "    \n",
    "    # Determine the maximum dimensions among all voxel grids\n",
    "    max_shape = [0, 0, 0]\n",
    "    for mesh in scene.geometry.values():\n",
    "        voxel_grid = mesh.voxelized(pitch=1.0 / resolution)\n",
    "        max_shape = [max(s, t) for s, t in zip(max_shape, voxel_grid.shape)]\n",
    "    \n",
    "    # Voxelization and resizing for each mesh in the scene\n",
    "    voxel_grids = []\n",
    "    for mesh in scene.geometry.values():\n",
    "        # Voxelization\n",
    "        voxel_grid = mesh.voxelized(pitch=1.0 / resolution)\n",
    "        \n",
    "        # Resize voxel grid to the maximum dimensions\n",
    "        voxel_grid = resize_voxel_grid(voxel_grid, target_shape=max_shape)\n",
    "        \n",
    "        # Convert voxel grid to tensor\n",
    "        voxel_tensor = torch.tensor(voxel_grid, dtype=torch.float32)\n",
    "        voxel_grids.append(voxel_tensor)\n",
    "    \n",
    "    return torch.stack(voxel_grids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing .glb files\n",
    "glb_dir = r\"C:\\Users\\rr858\\.objaverse\\hf-objaverse-v1\\glbs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.glb\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      7\u001b[0m     glb_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(glb_dir, file_name)\n\u001b[1;32m----> 8\u001b[0m     voxel_grid \u001b[38;5;241m=\u001b[39m \u001b[43mglb_to_voxels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mglb_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvoxel_resolution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     voxel_grids\u001b[38;5;241m.\u001b[39mappend(voxel_grid)\n",
      "Cell \u001b[1;32mIn[94], line 21\u001b[0m, in \u001b[0;36mglb_to_voxels\u001b[1;34m(glb_file, resolution)\u001b[0m\n\u001b[0;32m     18\u001b[0m voxel_grid \u001b[38;5;241m=\u001b[39m mesh\u001b[38;5;241m.\u001b[39mvoxelized(pitch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m resolution)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Resize voxel grid to the maximum dimensions\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m voxel_grid \u001b[38;5;241m=\u001b[39m \u001b[43mresize_voxel_grid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvoxel_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Convert voxel grid to tensor\u001b[39;00m\n\u001b[0;32m     24\u001b[0m voxel_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(voxel_grid, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "Cell \u001b[1;32mIn[93], line 20\u001b[0m, in \u001b[0;36mresize_voxel_grid\u001b[1;34m(voxel_grid, target_shape)\u001b[0m\n\u001b[0;32m     17\u001b[0m scale_factors \u001b[38;5;241m=\u001b[39m [t \u001b[38;5;241m/\u001b[39m s \u001b[38;5;28;01mfor\u001b[39;00m s, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(dense_voxel_grid\u001b[38;5;241m.\u001b[39mshape, target_shape)]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Resize voxel grid using zoom\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m resized_voxel_grid \u001b[38;5;241m=\u001b[39m \u001b[43mzoom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdense_voxel_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzoom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale_factors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnearest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resized_voxel_grid\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\scipy\\ndimage\\_interpolation.py:788\u001b[0m, in \u001b[0;36mzoom\u001b[1;34m(input, zoom, output, order, mode, cval, prefilter, grid_mode)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prefilter \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    787\u001b[0m     padded, npad \u001b[38;5;241m=\u001b[39m _prepad_for_spline_filter(\u001b[38;5;28minput\u001b[39m, mode, cval)\n\u001b[1;32m--> 788\u001b[0m     filtered \u001b[38;5;241m=\u001b[39m \u001b[43mspline_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    791\u001b[0m     npad \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\scipy\\ndimage\\_interpolation.py:191\u001b[0m, in \u001b[0;36mspline_filter\u001b[1;34m(input, order, output, mode)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m order \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mndim):\n\u001b[1;32m--> 191\u001b[0m         \u001b[43mspline_filter1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m output\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\scipy\\ndimage\\_interpolation.py:132\u001b[0m, in \u001b[0;36mspline_filter1d\u001b[1;34m(input, order, axis, output, mode)\u001b[0m\n\u001b[0;32m    130\u001b[0m     mode \u001b[38;5;241m=\u001b[39m _ni_support\u001b[38;5;241m.\u001b[39m_extend_mode_to_code(mode)\n\u001b[0;32m    131\u001b[0m     axis \u001b[38;5;241m=\u001b[39m normalize_axis_index(axis, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mndim)\n\u001b[1;32m--> 132\u001b[0m     \u001b[43m_nd_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspline_filter1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Resolution for voxel grid\n",
    "voxel_resolution = 64\n",
    "# Iterate through .glb files and voxelize them\n",
    "voxel_grids = []\n",
    "for file_name in os.listdir(glb_dir):\n",
    "    if file_name.endswith(\".glb\"):\n",
    "        glb_file = os.path.join(glb_dir, file_name)\n",
    "        voxel_grid = glb_to_voxels(glb_file, resolution=voxel_resolution)\n",
    "        voxel_grids.append(voxel_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally perform data augmentation and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list of voxel grids to a tensor\n",
    "voxel_grids_tensor = torch.stack(voxel_grids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the preprocessed voxel grids tensor\n",
    "torch.save(voxel_grids_tensor, \"preprocessed_voxel_grids.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nYhKLJUnwwlg",
    "outputId": "eb4246fe-e55d-4689-9489-63df3de393d4"
   },
   "outputs": [],
   "source": [
    "!pip install trimesh --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xYa72nn-wwfb",
    "outputId": "f73c6e25-465a-4895-88db-b95d4542fd18"
   },
   "outputs": [],
   "source": [
    "lvis_annotations = obx.load_lvis_annotations()\n",
    "lvis_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rdft0n1l2Xmx"
   },
   "source": [
    "use pandas and serialize and sort the descriptions of the 3d model like face count, vertex_count texture count and size, tags, description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.17.1-cp310-cp310-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.23.5)\n",
      "Collecting torch==2.2.1 (from torchvision)\n",
      "  Downloading torch-2.2.1-cp310-cp310-win_amd64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.2.1->torchvision) (3.9.0)\n",
      "Collecting typing-extensions>=4.8.0 (from torch==2.2.1->torchvision)\n",
      "  Downloading typing_extensions-4.10.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.2.1->torchvision) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.2.1->torchvision) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.2.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.2.1->torchvision) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch==2.2.1->torchvision) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch==2.2.1->torchvision) (1.2.1)\n",
      "Downloading torchvision-0.17.1-cp310-cp310-win_amd64.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 36.1 MB/s eta 0:00:00\n",
      "Downloading torch-2.2.1-cp310-cp310-win_amd64.whl (198.6 MB)\n",
      "   ---------------------------------------- 0.0/198.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 4.6/198.6 MB 147.3 MB/s eta 0:00:02\n",
      "   - ------------------------------------- 10.1/198.6 MB 129.6 MB/s eta 0:00:02\n",
      "   --- ----------------------------------- 15.8/198.6 MB 108.8 MB/s eta 0:00:02\n",
      "   ---- ---------------------------------- 21.3/198.6 MB 131.2 MB/s eta 0:00:02\n",
      "   ----- --------------------------------- 26.4/198.6 MB 131.2 MB/s eta 0:00:02\n",
      "   ------ -------------------------------- 31.6/198.6 MB 129.5 MB/s eta 0:00:02\n",
      "   ------- ------------------------------- 36.6/198.6 MB 110.0 MB/s eta 0:00:02\n",
      "   -------- ------------------------------ 41.8/198.6 MB 131.2 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 44.1/198.6 MB 81.8 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 47.8/198.6 MB 81.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 54.2/198.6 MB 93.0 MB/s eta 0:00:02\n",
      "   ----------- --------------------------- 60.7/198.6 MB 131.2 MB/s eta 0:00:02\n",
      "   ------------ -------------------------- 65.8/198.6 MB 110.0 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 70.7/198.6 MB 93.9 MB/s eta 0:00:02\n",
      "   -------------- ------------------------ 76.2/198.6 MB 108.8 MB/s eta 0:00:02\n",
      "   ---------------- ---------------------- 81.6/198.6 MB 108.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 86.6/198.6 MB 93.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 89.3/198.6 MB 93.9 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 93.5/198.6 MB 73.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 98.3/198.6 MB 81.8 MB/s eta 0:00:02\n",
      "   ------------------- ------------------ 102.9/198.6 MB 110.0 MB/s eta 0:00:01\n",
      "   -------------------- ------------------ 106.9/198.6 MB 93.9 MB/s eta 0:00:01\n",
      "   --------------------- ----------------- 110.9/198.6 MB 93.9 MB/s eta 0:00:01\n",
      "   ---------------------- ---------------- 115.3/198.6 MB 93.9 MB/s eta 0:00:01\n",
      "   ---------------------- --------------- 119.7/198.6 MB 108.8 MB/s eta 0:00:01\n",
      "   ------------------------ -------------- 124.5/198.6 MB 93.9 MB/s eta 0:00:01\n",
      "   ------------------------- ------------- 128.7/198.6 MB 93.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------ 132.7/198.6 MB 81.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------ 136.9/198.6 MB 93.9 MB/s eta 0:00:01\n",
      "   --------------------------- ----------- 141.2/198.6 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------- ---------- 146.3/198.6 MB 108.8 MB/s eta 0:00:01\n",
      "   ----------------------------- -------- 151.6/198.6 MB 129.5 MB/s eta 0:00:01\n",
      "   ----------------------------- -------- 155.6/198.6 MB 110.0 MB/s eta 0:00:01\n",
      "   ------------------------------ ------- 160.4/198.6 MB 131.2 MB/s eta 0:00:01\n",
      "   ------------------------------- ------ 165.2/198.6 MB 108.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ----- 170.7/198.6 MB 131.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 174.4/198.6 MB 93.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 178.9/198.6 MB 93.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 184.3/198.6 MB 93.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ - 189.1/198.6 MB 108.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ - 193.3/198.6 MB 108.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  197.8/198.6 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 93.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 93.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 93.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 93.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 93.9 MB/s eta 0:00:01\n",
      "   --------------------------------------- 198.6/198.6 MB 29.7 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Installing collected packages: typing-extensions, torch, torchvision\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.1\n",
      "    Uninstalling torch-1.12.1:\n",
      "      Successfully uninstalled torch-1.12.1\n",
      "Successfully installed torch-2.2.1 torchvision-0.17.1 typing-extensions-4.10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\rr858\\AppData\\Local\\Temp\\pip-uninstall-0412ho_y'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory for dataset\n",
    "dataroot = \"data/celeba\"\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 2\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 128\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 64\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 64\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# Beta1 hyperparameter for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "PUMpxaZM2XBy"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'SymInt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdset\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mvutils\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\torchvision\\__init__.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodulefinder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Module\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\torchvision\\_meta_registrations.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_custom_ops\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlibrary\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Ensure that torch.ops.torchvision is visible\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\torch\\_custom_ops.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_custom_op\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      4\u001b[0m     _custom_op_with_schema,\n\u001b[0;32m      5\u001b[0m     _find_custom_op,\n\u001b[0;32m      6\u001b[0m     infer_schema,\n\u001b[0;32m      7\u001b[0m     parse_qualname,\n\u001b[0;32m      8\u001b[0m     validate_namespace,\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlibrary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_ctx\n\u001b[0;32m     12\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom_op\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimpl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimpl_backward\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     19\u001b[0m ]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\torch\\_custom_op\\impl.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_C\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlibrary\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mlibrary\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_library\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabstract_impl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AbstractImplCtx\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlibrary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_ctx\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autograd_kernel_indirection, construct_autograd_kernel\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\torch\\_library\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_library\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabstract_impl\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_library\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimple_registry\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_library\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\torch\\_library\\abstract_impl.py:117\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    114\u001b[0m         global_ctx_getter \u001b[38;5;241m=\u001b[39m prev\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAbstractImplCtx\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;124;03m    Context object for writing abstract implementations for custom operators.\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, _shape_env, _op):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\torch\\_library\\abstract_impl.py:126\u001b[0m, in \u001b[0;36mAbstractImplCtx\u001b[1;34m()\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape_env \u001b[38;5;241m=\u001b[39m _shape_env\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op \u001b[38;5;241m=\u001b[39m _op\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_unbacked_symint\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSymInt\u001b[49m:\n\u001b[0;32m    127\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    128\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_unbacked_symint is deprecated, please use new_dynamic_size instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    129\u001b[0m     )\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_dynamic_size(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmin\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute 'SymInt'"
     ]
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "torch.use_deterministic_algorithms(True) # Needed for reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##mock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3836733143.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[31], line 11\u001b[1;36m\u001b[0m\n\u001b[1;33m    dataloader = torch.utils.data.DataLoader([for uid in uids : objects[uid]], batch_size=batch_size,\u001b[0m\n\u001b[1;37m                                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# We can use an image folder dataset the way we have it setup.\n",
    "# Create the dataset\n",
    "dataset = dset.ImageFolder(root=dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(image_size),\n",
    "                               transforms.CenterCrop(image_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "# Create the dataloader\n",
    "dataloader = torch.utils.data.DataLoader([for uid in uids : objects[uid]], batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=workers)\n",
    "\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n",
    "# Plot some training images\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original GAN Code (in PyTorch)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        # ... (architecture details)\n",
    "#         self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf*8),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*4),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*2),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            \n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the discriminator class\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        # ... (architecture details)\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(True),\n",
    "            \n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*2),\n",
    "            nn.LeakyReLU(0.2, inplace = True),\n",
    "            \n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*4),\n",
    "            nn.LeakyReLU(0.2, inplace = True),\n",
    "            \n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace = True),\n",
    "            \n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create generator and discriminator instances\n",
    "generator = Generator()\n",
    "print(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=True)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (12): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "discriminator = Discriminator()\n",
    "print(discriminator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize the ``BCELoss`` function\n",
    "# criterion = nn.BCELoss()\n",
    "\n",
    "# # Create batch of latent vectors that we will use to visualize\n",
    "# #  the progression of the generator\n",
    "# fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "# # Establish convention for real and fake labels during training\n",
    "# real_label = 1.\n",
    "# fake_label = 0.\n",
    "\n",
    "# # Setup Adam optimizers for both G and D\n",
    "# optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "# optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=0.001)\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(1000):\n",
    "    # ... (training details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock data for testing\n",
    "mock_data = torch.tensor([[0, 1, 0, 0, 1, 1, 1],\n",
    "                          [1, 0, 1, 1, 0, 0, 1],\n",
    "                          [0, 0, 1, 1, 1, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print mock data and generated results\n",
    "print(\"Mock data:\")\n",
    "print(mock_data)\n",
    "print(\"\\nGenerated data:\")\n",
    "print(generator(mock_data).round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/black0017/3D-GAN-pytorch/blob/master/models/GAN3D.py"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
